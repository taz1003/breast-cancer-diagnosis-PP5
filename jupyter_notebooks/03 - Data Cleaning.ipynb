{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Cleaning Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Prepare the data sets for further analysis.\n",
        "* Load and inspect the data prepared during data collection.\n",
        "* Data Cleaning.\n",
        "* Conclusion and next steps.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* /outputs/datasets/collection/breast-cancer.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate cleaned Train and Test sets, both saved under outputs/datasets/cleaned\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* As previously mentioned this projects relays on the guidelines provided in the walk through projects, and the lessons provided along the course (especially in the Predictive Analysis)\n",
        "* Therefore, this notebook will be relating the Data Preparation step of Crisp-DM methodology.\n",
        "* ***Don't forget Garbage In, Garbage out.***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\stazr\\\\OneDrive\\\\Documents\\\\vscode-projects\\\\breast-cancer-diagnosis-PP5\\\\jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\stazr\\\\OneDrive\\\\Documents\\\\vscode-projects\\\\breast-cancer-diagnosis-PP5'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Collected Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>1</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>1</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>1</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>1</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>1</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302          1        17.99         10.38          122.80     1001.0   \n",
              "1    842517          1        20.57         17.77          132.90     1326.0   \n",
              "2  84300903          1        19.69         21.25          130.00     1203.0   \n",
              "3  84348301          1        11.42         20.38           77.58      386.1   \n",
              "4  84358402          1        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
              "0  ...         25.38          17.33           184.60      2019.0   \n",
              "1  ...         24.99          23.41           158.80      1956.0   \n",
              "2  ...         23.57          25.53           152.50      1709.0   \n",
              "3  ...         14.91          26.50            98.87       567.7   \n",
              "4  ...         22.54          16.67           152.20      1575.0   \n",
              "\n",
              "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
              "0            0.1622             0.6656           0.7119                0.2654   \n",
              "1            0.1238             0.1866           0.2416                0.1860   \n",
              "2            0.1444             0.4245           0.4504                0.2430   \n",
              "3            0.2098             0.8663           0.6869                0.2575   \n",
              "4            0.1374             0.2050           0.4000                0.1625   \n",
              "\n",
              "   symmetry_worst  fractal_dimension_worst  \n",
              "0          0.4601                  0.11890  \n",
              "1          0.2750                  0.08902  \n",
              "2          0.3613                  0.08758  \n",
              "3          0.6638                  0.17300  \n",
              "4          0.2364                  0.07678  \n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('outputs/datasets/collection/breast-cancer.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will check the distribution and shape from a variable with missing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
        "vars_with_missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (569, 32)\n",
            "\n",
            "Data Types:\n",
            " id                           int64\n",
            "diagnosis                    int64\n",
            "radius_mean                float64\n",
            "texture_mean               float64\n",
            "perimeter_mean             float64\n",
            "area_mean                  float64\n",
            "smoothness_mean            float64\n",
            "compactness_mean           float64\n",
            "concavity_mean             float64\n",
            "concave points_mean        float64\n",
            "symmetry_mean              float64\n",
            "fractal_dimension_mean     float64\n",
            "radius_se                  float64\n",
            "texture_se                 float64\n",
            "perimeter_se               float64\n",
            "area_se                    float64\n",
            "smoothness_se              float64\n",
            "compactness_se             float64\n",
            "concavity_se               float64\n",
            "concave points_se          float64\n",
            "symmetry_se                float64\n",
            "fractal_dimension_se       float64\n",
            "radius_worst               float64\n",
            "texture_worst              float64\n",
            "perimeter_worst            float64\n",
            "area_worst                 float64\n",
            "smoothness_worst           float64\n",
            "compactness_worst          float64\n",
            "concavity_worst            float64\n",
            "concave points_worst       float64\n",
            "symmetry_worst             float64\n",
            "fractal_dimension_worst    float64\n",
            "dtype: object\n",
            "\n",
            "Missing Values:\n",
            " id                         0\n",
            "diagnosis                  0\n",
            "radius_mean                0\n",
            "texture_mean               0\n",
            "perimeter_mean             0\n",
            "area_mean                  0\n",
            "smoothness_mean            0\n",
            "compactness_mean           0\n",
            "concavity_mean             0\n",
            "concave points_mean        0\n",
            "symmetry_mean              0\n",
            "fractal_dimension_mean     0\n",
            "radius_se                  0\n",
            "texture_se                 0\n",
            "perimeter_se               0\n",
            "area_se                    0\n",
            "smoothness_se              0\n",
            "compactness_se             0\n",
            "concavity_se               0\n",
            "concave points_se          0\n",
            "symmetry_se                0\n",
            "fractal_dimension_se       0\n",
            "radius_worst               0\n",
            "texture_worst              0\n",
            "perimeter_worst            0\n",
            "area_worst                 0\n",
            "smoothness_worst           0\n",
            "compactness_worst          0\n",
            "concavity_worst            0\n",
            "concave points_worst       0\n",
            "symmetry_worst             0\n",
            "fractal_dimension_worst    0\n",
            "dtype: int64\n",
            "\n",
            "Descriptive Stats:\n",
            "                  id   diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
            "count  5.690000e+02  569.000000   569.000000    569.000000      569.000000   \n",
            "mean   3.037183e+07    0.372583    14.127292     19.289649       91.969033   \n",
            "std    1.250206e+08    0.483918     3.524049      4.301036       24.298981   \n",
            "min    8.670000e+03    0.000000     6.981000      9.710000       43.790000   \n",
            "25%    8.692180e+05    0.000000    11.700000     16.170000       75.170000   \n",
            "50%    9.060240e+05    0.000000    13.370000     18.840000       86.240000   \n",
            "75%    8.813129e+06    1.000000    15.780000     21.800000      104.100000   \n",
            "max    9.113205e+08    1.000000    28.110000     39.280000      188.500000   \n",
            "\n",
            "         area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
            "count   569.000000       569.000000        569.000000      569.000000   \n",
            "mean    654.889104         0.096360          0.104341        0.088799   \n",
            "std     351.914129         0.014064          0.052813        0.079720   \n",
            "min     143.500000         0.052630          0.019380        0.000000   \n",
            "25%     420.300000         0.086370          0.064920        0.029560   \n",
            "50%     551.100000         0.095870          0.092630        0.061540   \n",
            "75%     782.700000         0.105300          0.130400        0.130700   \n",
            "max    2501.000000         0.163400          0.345400        0.426800   \n",
            "\n",
            "       concave points_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
            "count           569.000000  ...    569.000000     569.000000       569.000000   \n",
            "mean              0.048919  ...     16.269190      25.677223       107.261213   \n",
            "std               0.038803  ...      4.833242       6.146258        33.602542   \n",
            "min               0.000000  ...      7.930000      12.020000        50.410000   \n",
            "25%               0.020310  ...     13.010000      21.080000        84.110000   \n",
            "50%               0.033500  ...     14.970000      25.410000        97.660000   \n",
            "75%               0.074000  ...     18.790000      29.720000       125.400000   \n",
            "max               0.201200  ...     36.040000      49.540000       251.200000   \n",
            "\n",
            "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
            "count   569.000000        569.000000         569.000000       569.000000   \n",
            "mean    880.583128          0.132369           0.254265         0.272188   \n",
            "std     569.356993          0.022832           0.157336         0.208624   \n",
            "min     185.200000          0.071170           0.027290         0.000000   \n",
            "25%     515.300000          0.116600           0.147200         0.114500   \n",
            "50%     686.500000          0.131300           0.211900         0.226700   \n",
            "75%    1084.000000          0.146000           0.339100         0.382900   \n",
            "max    4254.000000          0.222600           1.058000         1.252000   \n",
            "\n",
            "       concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
            "count            569.000000      569.000000               569.000000  \n",
            "mean               0.114606        0.290076                 0.083946  \n",
            "std                0.065732        0.061867                 0.018061  \n",
            "min                0.000000        0.156500                 0.055040  \n",
            "25%                0.064930        0.250400                 0.071460  \n",
            "50%                0.099930        0.282200                 0.080040  \n",
            "75%                0.161400        0.317900                 0.092080  \n",
            "max                0.291000        0.663800                 0.207500  \n",
            "\n",
            "[8 rows x 32 columns]\n",
            "\n",
            "Sample:\n",
            "          id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
            "0    842302          1        17.99         10.38          122.80     1001.0   \n",
            "1    842517          1        20.57         17.77          132.90     1326.0   \n",
            "2  84300903          1        19.69         21.25          130.00     1203.0   \n",
            "3  84348301          1        11.42         20.38           77.58      386.1   \n",
            "4  84358402          1        20.29         14.34          135.10     1297.0   \n",
            "\n",
            "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
            "0          0.11840           0.27760          0.3001              0.14710   \n",
            "1          0.08474           0.07864          0.0869              0.07017   \n",
            "2          0.10960           0.15990          0.1974              0.12790   \n",
            "3          0.14250           0.28390          0.2414              0.10520   \n",
            "4          0.10030           0.13280          0.1980              0.10430   \n",
            "\n",
            "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
            "0  ...         25.38          17.33           184.60      2019.0   \n",
            "1  ...         24.99          23.41           158.80      1956.0   \n",
            "2  ...         23.57          25.53           152.50      1709.0   \n",
            "3  ...         14.91          26.50            98.87       567.7   \n",
            "4  ...         22.54          16.67           152.20      1575.0   \n",
            "\n",
            "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
            "0            0.1622             0.6656           0.7119                0.2654   \n",
            "1            0.1238             0.1866           0.2416                0.1860   \n",
            "2            0.1444             0.4245           0.4504                0.2430   \n",
            "3            0.2098             0.8663           0.6869                0.2575   \n",
            "4            0.1374             0.2050           0.4000                0.1625   \n",
            "\n",
            "   symmetry_worst  fractal_dimension_worst  \n",
            "0          0.4601                  0.11890  \n",
            "1          0.2750                  0.08902  \n",
            "2          0.3613                  0.08758  \n",
            "3          0.6638                  0.17300  \n",
            "4          0.2364                  0.07678  \n",
            "\n",
            "[5 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "def df_describe(df):\n",
        "    # Basic stats\n",
        "    print(\"Shape:\", df.shape)\n",
        "    print(\"\\nData Types:\\n\", df.dtypes)\n",
        "    print(\"\\nMissing Values:\\n\", df.isna().sum())\n",
        "    print(\"\\nDescriptive Stats:\\n\", df.describe(include='all'))\n",
        "    print(\"\\nSample:\\n\", df.head())\n",
        "\n",
        "df_describe(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We notice that there are no variables with missing data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Correlation and PPS Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We will create a function that is in compliance with updated pandas and ppscore.\n",
        "* This will get rid of any deprecated warning that may come."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pandas.api.types import CategoricalDtype\n",
        "import ppscore.calculation as pps_calc\n",
        "\n",
        "def _is_categorical_dtype(series):\n",
        "    \"\"\"\n",
        "    Check if a pandas Series is of categorical dtype.\n",
        "    This fixes the PPS deprecation warning.\n",
        "    \"\"\"\n",
        "    return isinstance(series.dtype, CategoricalDtype)\n",
        "\n",
        "pps_calc.is_categorical_dtype = _is_categorical_dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "# This line is used to display plots inline in Jupyter notebooks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the following code cell we will -\n",
        "* Create a function to plot a heatmap to visualize spearman and pearson correlations among the variables.\n",
        "* Create a function to plot a heatmap to visualize Power Predictive Score (PPS) among the variables.\n",
        "* Create a function to calculate correlation and PPS.\n",
        "* Create a function to display the heatmaps ini succession."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "\n",
        "\n",
        "def heatmap_corr(df, threshold, figsize=(20, 15), font_annot=10, rotation=45):\n",
        "    \"\"\"\n",
        "    Plot a heatmap for the correlation matrix.\n",
        "    Used to visualize spearman and pearson correlations.\n",
        "    \"\"\"\n",
        "    if len(df.columns) > 1:\n",
        "        mask = np.zeros_like(df, dtype=bool)\n",
        "        mask[np.triu_indices_from(mask)] = True\n",
        "        mask[abs(df) < threshold] = True\n",
        "\n",
        "        fig, axes = plt.subplots(figsize=figsize)\n",
        "        sns.heatmap(df, annot=True, fmt=\".2f\", xticklabels=True, yticklabels=True,\n",
        "                    mask=mask, cmap='plasma_r', annot_kws={\"size\": font_annot}, ax=axes,\n",
        "                    linewidth=0.5, cbar_kws={'shrink': 0.5})\n",
        "        axes.set_yticklabels(df.columns, rotation=0)\n",
        "        axes.set_xticklabels(df.columns, rotation=rotation, ha='right')\n",
        "        plt.ylim(len(df.columns), 0)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def heatmap_pps(df, threshold, figsize=(20, 15), font_annot=10, rotation=45):\n",
        "    \"\"\"\n",
        "    Plot a heatmap for the Power Predictive Score (PPS) matrix.\n",
        "    Used to visualize the predictive power of features.\n",
        "    \"\"\"\n",
        "    if len(df.columns) > 1:\n",
        "        mask = np.zeros_like(df, dtype=bool)\n",
        "        mask[abs(df) < threshold] = True\n",
        "        fig, ax = plt.subplots(figsize=figsize)\n",
        "        sns.heatmap(df, annot=True, fmt=\".2f\", xticklabels=True, yticklabels=True,\n",
        "                    mask=mask, cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
        "                    linewidth=0.05, linecolor='grey', cbar_kws={'shrink': 0.5})\n",
        "        ax.set_yticklabels(df.columns, rotation=0)\n",
        "        ax.set_xticklabels(df.columns, rotation=rotation, ha='right')\n",
        "        plt.ylim(len(df.columns), 0)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "    \"\"\"\n",
        "    Calculate correlation and Power Predictive Score (PPS) matrices.\n",
        "    \"\"\"\n",
        "    df_corr_spearman = df.corr(method=\"spearman\", numeric_only=True)\n",
        "    df_corr_pearson = df.corr(method=\"pearson\", numeric_only=True)\n",
        "\n",
        "    pps_matrix_raw = pps.matrix(df)\n",
        "    pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "    pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "    print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
        "    print(pps_score_stats.round(3))\n",
        "\n",
        "    return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix, CorrThreshold, PPS_Threshold,\n",
        "                    figsize=(20, 12), font_annot=8):\n",
        "    \"\"\"\n",
        "    Display the correlation and PPS heatmaps.\n",
        "    \"\"\"\n",
        "    print(\"\\n\")\n",
        "    print(\"* Analyse how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "    print(\"* Analyse multi-colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "    print(\"It evaluates monotonic relationship \\n\")\n",
        "    heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "    print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "    heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
        "    print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "        f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "    heatmap_pps(df=pps_matrix, threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculate Correlations and Power Predictive Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Display Heatmaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
        "                df_corr_spearman = df_corr_spearman, \n",
        "                pps_matrix = pps_matrix,\n",
        "                CorrThreshold = 0.4, PPS_Threshold =0.2,\n",
        "                figsize=(20,15), font_annot=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Correlation and Power Predictive Score (PPS) Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data presented in the spearman and pearson reports and PPS matrix shows that -\n",
        "* The worst (largest) values of radius, texture, area and perimeter correlate highly with their own mean values, not only reciprocally but also amongst each other.\n",
        "* The correlativity among the mean and worst values of concave variables are very high.\n",
        "* Nearly all of the variables show correlations of some sort, weak or strong. So for our future ML cases its better to retain them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Assess missing data levels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>1</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.8</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.6</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>1</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.9</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.8</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>1</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.0</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.5</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302          1        17.99         10.38           122.8     1001.0   \n",
              "1    842517          1        20.57         17.77           132.9     1326.0   \n",
              "2  84300903          1        19.69         21.25           130.0     1203.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "\n",
              "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
              "0  ...         25.38          17.33            184.6      2019.0   \n",
              "1  ...         24.99          23.41            158.8      1956.0   \n",
              "2  ...         23.57          25.53            152.5      1709.0   \n",
              "\n",
              "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
              "0            0.1622             0.6656           0.7119                0.2654   \n",
              "1            0.1238             0.1866           0.2416                0.1860   \n",
              "2            0.1444             0.4245           0.4504                0.2430   \n",
              "\n",
              "   symmetry_worst  fractal_dimension_worst  \n",
              "0          0.4601                  0.11890  \n",
              "1          0.2750                  0.08902  \n",
              "2          0.3613                  0.08758  \n",
              "\n",
              "[3 rows x 32 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def EvaluateMissingData(df):\n",
        "    missing_data_absolute = df.isnull().sum()\n",
        "    missing_data_percentage = round(missing_data_absolute/len(df)*100, 2)\n",
        "    df_missing_data = (pd.DataFrame(\n",
        "                            data={\"RowsWithMissingData\": missing_data_absolute,\n",
        "                                \"PercentageOfDataset\": missing_data_percentage,\n",
        "                                \"DataType\": df.dtypes}\n",
        "                                    )\n",
        "                        .sort_values(by=['PercentageOfDataset'], ascending=False)\n",
        "                        .query(\"PercentageOfDataset > 0\")\n",
        "                        )\n",
        "\n",
        "    return df_missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowsWithMissingData</th>\n",
              "      <th>PercentageOfDataset</th>\n",
              "      <th>DataType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [RowsWithMissingData, PercentageOfDataset, DataType]\n",
              "Index: []"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "EvaluateMissingData(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Again, we confirm that there are no variables with missing data, so we can procede onto the next step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Cleaning Spreadsheet Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Cleaning Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We will split the dataset into train and test sets, the train set containing 80% of the total dataset and the test set containing 20%.\n",
        "\n",
        "* We will take the **Drop Variables** imputation approach and drop `id` variable from our train and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "TrainSet, TestSet, _, __ = train_test_split(\n",
        "                                        df,\n",
        "                                        df['diagnosis'],\n",
        "                                        test_size=0.2,\n",
        "                                        random_state=0)\n",
        "\n",
        "print(f\"TrainSet shape: {TrainSet.shape} \\nTestSet shape: {TestSet.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Drop Variables\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 1: imputation approach: Drop Variables\n",
        "* Step 2: Select variables to apply the imputation approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variables_method = ['id' ]\n",
        "\n",
        "print(f\"* {len(variables_method)} variables to drop \\n\\n\"\n",
        "    f\"{variables_method}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are dropping `id` since it is a unique identifier for each patient, it doesn't add any relevant value to our diagnosis prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 3: Create a separate DataFrame applying this imputation approach to the selected variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.selection import DropFeatures\n",
        "imputer = DropFeatures(features_to_drop=variables_method)\n",
        "imputer.fit(TrainSet)\n",
        "df_method = imputer.transform(TrainSet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 4: Assess the effect on the variable's distribution.\n",
        "\n",
        "In this case, there is no effect on the distribution of the variable, since we are not removing rows, but columns. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 5: Apply the transformation to our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.selection import DropFeatures\n",
        "imputer = DropFeatures(features_to_drop=variables_method)\n",
        "imputer.fit(TrainSet)\n",
        "\n",
        "TrainSet, TestSet = imputer.transform(TrainSet) , imputer.transform(TestSet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 6: Conclude the data cleaning process with dataset assesment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TrainSet.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TestSet.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs(name='outputs/datasets/cleaned') # create outputs/datasets/cleaned folder\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Saving the Train Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TrainSet.to_csv(\"outputs/datasets/cleaned/TrainSetCleaned.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Saving the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TestSet.to_csv(\"outputs/datasets/cleaned/TestSetCleaned.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Being satisfied with our data cleaning process, we save the Train and Test dataset and move onto the Feature Engineering process."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
