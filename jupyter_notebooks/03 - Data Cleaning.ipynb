{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Cleaning Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Prepare the data sets for further analysis.\n",
        "* Load and inspect the data prepared during data collection.\n",
        "* Data Cleaning.\n",
        "* Conclusion and next steps.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* /outputs/datasets/collection/breast-cancer.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate cleaned Train and Test sets, both saved under outputs/datasets/cleaned\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* As previously mentioned this projects relays on the guidelines provided in the walk through projects, and the lessons provided along the course (especially in the Predictive Analysis)\n",
        "* Therefore, this notebook will be relating the Data Preparation step of Crisp-DM methodology.\n",
        "* ***Don't forget Garbage In, Garbage out.***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Collected Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('outputs/datasets/collection/breast-cancer.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will check the distribution and shape from a variable with missing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
        "vars_with_missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "if vars_with_missing_data:\n",
        "    profile = ProfileReport(df=df[vars_with_missing_data], minimal=True)\n",
        "    profile.to_notebook_iframe()\n",
        "else:\n",
        "    print(\"There are no variables with missing data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We notice that there are no variables with missing data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Correlation and PPS Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We will create a function that is in compliance with updated pandas and ppscore.\n",
        "* This will get rid of any deprecated warning that may come."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pandas.api.types import CategoricalDtype\n",
        "import ppscore.calculation as pps_calc\n",
        "\n",
        "def _is_categorical_dtype(series):\n",
        "    \"\"\"\n",
        "    Check if a pandas Series is of categorical dtype.\n",
        "    This fixes the PPS deprecation warning.\n",
        "    \"\"\"\n",
        "    return isinstance(series.dtype, CategoricalDtype)\n",
        "\n",
        "pps_calc.is_categorical_dtype = _is_categorical_dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the following code cell we will -\n",
        "* Create a function to plot a heatmap to visualize spearman and pearson correlations among the variables.\n",
        "* Create a function to plot a heatmap to visualize Power Predictive Score (PPS) among the variables.\n",
        "* Create a function to calculate correlation and PPS.\n",
        "* Create a function to display the heatmaps ini succession."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "\n",
        "\n",
        "def heatmap_corr(df, threshold, figsize=(20, 15), font_annot=10, rotation=45):\n",
        "    \"\"\"\n",
        "    Plot a heatmap for the correlation matrix.\n",
        "    Used to visualize spearman and pearson correlations.\n",
        "    \"\"\"\n",
        "    if len(df.columns) > 1:\n",
        "        mask = np.zeros_like(df, dtype=bool)\n",
        "        mask[np.triu_indices_from(mask)] = True\n",
        "        mask[abs(df) < threshold] = True\n",
        "\n",
        "        fig, axes = plt.subplots(figsize=figsize)\n",
        "        sns.heatmap(df, annot=True, fmt=\".2f\", xticklabels=True, yticklabels=True,\n",
        "                    mask=mask, cmap='plasma_r', annot_kws={\"size\": font_annot}, ax=axes,\n",
        "                    linewidth=0.5, cbar_kws={'shrink': 0.5})\n",
        "        axes.set_yticklabels(df.columns, rotation=0)\n",
        "        axes.set_xticklabels(df.columns, rotation=rotation, ha='right')\n",
        "        plt.ylim(len(df.columns), 0)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def heatmap_pps(df, threshold, figsize=(20, 15), font_annot=10, rotation=45):\n",
        "    \"\"\"\n",
        "    Plot a heatmap for the Power Predictive Score (PPS) matrix.\n",
        "    Used to visualize the predictive power of features.\n",
        "    \"\"\"\n",
        "    if len(df.columns) > 1:\n",
        "        mask = np.zeros_like(df, dtype=bool)\n",
        "        mask[abs(df) < threshold] = True\n",
        "        fig, ax = plt.subplots(figsize=figsize)\n",
        "        sns.heatmap(df, annot=True, fmt=\".2f\", xticklabels=True, yticklabels=True,\n",
        "                    mask=mask, cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
        "                    linewidth=0.05, linecolor='grey', cbar_kws={'shrink': 0.5})\n",
        "        ax.set_yticklabels(df.columns, rotation=0)\n",
        "        ax.set_xticklabels(df.columns, rotation=rotation, ha='right')\n",
        "        plt.ylim(len(df.columns), 0)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "    \"\"\"\n",
        "    Calculate correlation and Power Predictive Score (PPS) matrices.\n",
        "    \"\"\"\n",
        "    df_corr_spearman = df.corr(method=\"spearman\", numeric_only=True)\n",
        "    df_corr_pearson = df.corr(method=\"pearson\", numeric_only=True)\n",
        "\n",
        "    pps_matrix_raw = pps.matrix(df)\n",
        "    pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "    pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "    print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
        "    print(pps_score_stats.round(3))\n",
        "\n",
        "    return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix, CorrThreshold, PPS_Threshold,\n",
        "                    figsize=(20, 12), font_annot=8):\n",
        "    \"\"\"\n",
        "    Display the correlation and PPS heatmaps.\n",
        "    \"\"\"\n",
        "    print(\"\\n\")\n",
        "    print(\"* Analyse how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "    print(\"* Analyse multi-colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "    print(\"It evaluates monotonic relationship \\n\")\n",
        "    heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "    print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "    heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
        "    print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "        f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "    heatmap_pps(df=pps_matrix, threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculate Correlations and Power Predictive Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Display Heatmaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
        "                df_corr_spearman = df_corr_spearman, \n",
        "                pps_matrix = pps_matrix,\n",
        "                CorrThreshold = 0.4, PPS_Threshold =0.2,\n",
        "                figsize=(20,15), font_annot=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Correlation and Power Predictive Score (PPS) Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data presented in the spearman and pearson reports and PPS matrix shows that -\n",
        "* The worst (largest) values of radius, texture, area and perimeter correlate highly with their own mean values, not only reciprocally but also amongst each other.\n",
        "* The correlativity among the mean and worst values of concave variables are very high.\n",
        "* Nearly all of the variables show correlations of some sort, weak or strong. So for our future ML cases its better to retain them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Assess missing data levels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def EvaluateMissingData(df):\n",
        "    missing_data_absolute = df.isnull().sum()\n",
        "    missing_data_percentage = round(missing_data_absolute/len(df)*100, 2)\n",
        "    df_missing_data = (pd.DataFrame(\n",
        "                            data={\"RowsWithMissingData\": missing_data_absolute,\n",
        "                                \"PercentageOfDataset\": missing_data_percentage,\n",
        "                                \"DataType\": df.dtypes}\n",
        "                                    )\n",
        "                        .sort_values(by=['PercentageOfDataset'], ascending=False)\n",
        "                        .query(\"PercentageOfDataset > 0\")\n",
        "                        )\n",
        "\n",
        "    return df_missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EvaluateMissingData(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Again, we confirm that there are no variables with missing data, so we can procede onto the next step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Cleaning Spreadsheet Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Cleaning Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We will convert `diagnosis` values from `M` and `B` to `0` and `1` respectively so that the saved datasets will already have the target variable in a numeric format, so any ML model can consume it directly without extra preprocessing later.\n",
        "\n",
        "* We will split the dataset into train and test sets, the train set containing 80% of the total dataset and the test set containing 20%.\n",
        "\n",
        "* We will take the **Drop Variables** imputation approach and drop `id` variable from our train and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert 'diagnosis' values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['diagnosis'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will convert the diagnosis to binary values\n",
        "\n",
        "* `M` = 1 (for Malignant)\n",
        "* `B` = 0 (for Benign)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***!! Warning !!***\n",
        "**( Do not run the next code cell twice. `diagnosis` will lose all its value )**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
        "df.tail(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "TrainSet, TestSet, _, __ = train_test_split(\n",
        "                                        df,\n",
        "                                        df['diagnosis'],\n",
        "                                        test_size=0.2,\n",
        "                                        random_state=0)\n",
        "\n",
        "print(f\"TrainSet shape: {TrainSet.shape} \\nTestSet shape: {TestSet.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Drop Variables\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 1: imputation approach: Drop Variables\n",
        "* Step 2: Select variables to apply the imputation approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variables_method = ['id' ]\n",
        "\n",
        "print(f\"* {len(variables_method)} variables to drop \\n\\n\"\n",
        "    f\"{variables_method}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are dropping `id` since it is a unique identifier for each patient, it doesn't add any relevant value to our diagnosis prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 3: Create a separate DataFrame applying this imputation approach to the selected variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.selection import DropFeatures\n",
        "imputer = DropFeatures(features_to_drop=variables_method)\n",
        "imputer.fit(TrainSet)\n",
        "df_method = imputer.transform(TrainSet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 4: Assess the effect on the variable's distribution.\n",
        "\n",
        "In this case, there is no effect on the distribution of the variable, since we are not removing rows, but columns. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 5: Apply the transformation to our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.selection import DropFeatures\n",
        "imputer = DropFeatures(features_to_drop=variables_method)\n",
        "imputer.fit(TrainSet)\n",
        "\n",
        "TrainSet, TestSet = imputer.transform(TrainSet) , imputer.transform(TestSet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 6: Conclude the data cleaning process with dataset assesment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TrainSet.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TestSet.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs(name='outputs/datasets/cleaned') # create outputs/datasets/cleaned folder\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Saving the Train Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TrainSet.to_csv(\"outputs/datasets/cleaned/TrainSetCleaned.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Saving the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TestSet.to_csv(\"outputs/datasets/cleaned/TestSetCleaned.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Being satisfied with our data cleaning process, we save the Train and Test dataset and move onto the Feature Engineering process."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "3.12.1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
